{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2a28240",
   "metadata": {},
   "source": [
    "# 0.0 Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2235839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import inflection\n",
    "import numpy as np\n",
    "import datetime as dtt\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import warnings\n",
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.display import HTML\n",
    "from scipy import stats as ss\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da3e476",
   "metadata": {},
   "source": [
    "## 0.1. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8783a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramer_v(x, y):\n",
    "    cm = pd.crosstab(x, y).values\n",
    "    n = cm.sum()\n",
    "    r, k = cm.shape\n",
    "    chi2 = ss.chi2_contingency(cm)[0]\n",
    "    chi2corr = max(0, chi2 - (k-1)*(r-1)/(n-1))\n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    rcorr = r - (r-1)**2/(n-1)\n",
    "    \n",
    "    return np.sqrt((chi2corr/n)/(min(kcorr-1, rcorr-1)))\n",
    "\n",
    "def mean_absolute_percentage_error (y, yhat):\n",
    "    return np.mean(np.abs((y - yhat)/y))\n",
    "    \n",
    "def ml_error(model_name, y, yhat):\n",
    "    mae = mean_absolute_error(y, yhat)\n",
    "    mape = mean_absolute_percentage_error(y , yhat)\n",
    "    rmse = np.sqrt(mean_squared_error(y, yhat))\n",
    "    \n",
    "    return pd.DataFrame({'model name': model_name,\n",
    "                        'MAE': mae,\n",
    "                        'MAPE': mape,\n",
    "                        'RMSE': rmse}, index=[0])\n",
    "\n",
    "def cross_validation(x_training, kfold, model_name, model, verbose=False):\n",
    "    mae_list = []\n",
    "    mape_list = []\n",
    "    rmse_list = []\n",
    "    for k in reversed(range(1, kfold+1)):\n",
    "        if verbose:\n",
    "            print('\\nKFold Number{}'.format(k))\n",
    "        # start and end date for validation\n",
    "        validation_start_date = x_training['date'].max() - dtt.timedelta(days=k*6*7)\n",
    "        validation_end_date = x_training['date'].max() - dtt.timedelta(days=(k-1)*6*7)\n",
    "\n",
    "        # filtering dataset\n",
    "        training = x_training[x_training['date'] < validation_start_date]\n",
    "        validation = x_training[(x_training['date'] >= validation_start_date) & \n",
    "                                (x_training['date'] <= validation_end_date)]\n",
    "\n",
    "        # training and validation dataset\n",
    "        # training\n",
    "        xtraining = training.drop(['date', 'sales'], axis=1)\n",
    "        ytraining = training['sales']\n",
    "\n",
    "        # validation\n",
    "        xvalidation = validation.drop(['date', 'sales'], axis=1)\n",
    "        yvalidation = validation['sales']\n",
    "\n",
    "        # model\n",
    "        m = model.fit(xtraining, ytraining)\n",
    "\n",
    "        # prediction\n",
    "        yhat = m.predict(xvalidation)\n",
    "\n",
    "        # performance\n",
    "        m_result = ml_error(model_name, np.expm1(yvalidation), np.expm1(yhat))\n",
    "\n",
    "        # store performance of each kfold iteration\n",
    "        mae_list.append(m_result['MAE'])\n",
    "        mape_list.append(m_result['MAPE'])\n",
    "        rmse_list.append(m_result['RMSE'])\n",
    "    \n",
    "    return pd.DataFrame({'Model Name': model_name, \n",
    "                        'MAE CV': np.round(np.mean(mae_list), 2).astype(str) + ' +/- ' + np.round(np.std(mae_list), 2).astype(str) , \n",
    "                        'MAPE CV': np.round(np.mean(mape_list), 2).astype(str) + ' +/- ' + np.round(np.std(mape_list), 2).astype(str), \n",
    "                        'RMSE CV': np.round(np.mean(rmse_list), 2).astype(str) + ' +/- ' + np.round(np.std(rmse_list), 2).astype(str)}, \n",
    "                         index=[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cdf8f2",
   "metadata": {},
   "source": [
    "## 0.2 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e06885bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_raw = pd.read_csv(r'C:\\Users\\jota_\\Repositorios\\DS_producao\\Datasets_ds\\train.csv', low_memory=False)\n",
    "df_store_raw = pd.read_csv(r'C:\\Users\\jota_\\Repositorios\\DS_producao\\Datasets_ds\\store.csv', low_memory=False)\n",
    "\n",
    "#merge \n",
    "df_raw = pd.merge(df_sales_raw, df_store_raw, how = 'left', on='Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59be19a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14242325",
   "metadata": {},
   "source": [
    "# 1.0 Data description and transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f228e",
   "metadata": {},
   "source": [
    "## 1.1 Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b539abda",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_old = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', \n",
    "            'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', \n",
    "            'Promo2', 'Promo2SinceWeek','Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "\n",
    "snakecase = lambda x: inflection.underscore(x)\n",
    "\n",
    "cols_new = list(map(snakecase, cols_old))\n",
    "\n",
    "#Rename\n",
    "df1.columns = cols_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e559f2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store                                    int64\n",
      "day_of_week                              int64\n",
      "date                            datetime64[ns]\n",
      "sales                                    int64\n",
      "customers                                int64\n",
      "open                                     int64\n",
      "promo                                    int64\n",
      "state_holiday                           object\n",
      "school_holiday                           int64\n",
      "store_type                              object\n",
      "assortment                              object\n",
      "competition_distance                   float64\n",
      "competition_open_since_month           float64\n",
      "competition_open_since_year            float64\n",
      "promo2                                   int64\n",
      "promo2_since_week                      float64\n",
      "promo2_since_year                      float64\n",
      "promo_interval                          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df1['date'] = pd.to_datetime(df1['date'])\n",
    "print(df1.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc5fff4",
   "metadata": {},
   "source": [
    "## 1.2 Fillout NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74245eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#competition_distance             \n",
    "df1['competition_distance'] = df1['competition_distance'].apply(lambda x: 200000.0 if math.isnan(x) else x)\n",
    "\n",
    "#competition_open_since_month    \n",
    "\n",
    "df1['competition_open_since_month'] = df1.apply(lambda x: x['date'].month if math.isnan(x['competition_open_since_month']) \n",
    "                                                else x['competition_open_since_month'], axis=1) \n",
    "\n",
    "#competition_open_since_year     \n",
    "\n",
    "df1['competition_open_since_year'] = df1.apply(lambda x: x['date'].year if math.isnan(x['competition_open_since_year']) \n",
    "                                                else x['competition_open_since_year'], axis=1) \n",
    "\n",
    "#promo2_since_week    \n",
    "df1['promo2_since_week'] = df1.apply(lambda x: x['date'].week if math.isnan(x['promo2_since_week']) \n",
    "                                                else x['promo2_since_week'], axis=1)\n",
    "\n",
    "#promo2_since_year               \n",
    "df1['promo2_since_year'] = df1.apply(lambda x: x['date'].year if math.isnan(x['promo2_since_year']) \n",
    "                                                else x['promo2_since_year'], axis=1)\n",
    "                 \n",
    "#promo_interval\n",
    "df1['promo_interval'].fillna(0, inplace=True)\n",
    "\n",
    "month_map = {1: 'Jan', 2: 'Fev', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', \n",
    "             7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "\n",
    "df1['month_map'] = df1['date'].dt.month.map(month_map)\n",
    "\n",
    "df1['is_promo'] = df1[['promo_interval', 'month_map']].apply(\n",
    "    lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split(',') else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d8454a",
   "metadata": {},
   "source": [
    "## 1.3 Change dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd7a388e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store                                    int64\n",
       "day_of_week                              int64\n",
       "date                            datetime64[ns]\n",
       "sales                                    int64\n",
       "customers                                int64\n",
       "open                                     int64\n",
       "promo                                    int64\n",
       "state_holiday                           object\n",
       "school_holiday                           int64\n",
       "store_type                              object\n",
       "assortment                              object\n",
       "competition_distance                   float64\n",
       "competition_open_since_month           float64\n",
       "competition_open_since_year            float64\n",
       "promo2                                   int64\n",
       "promo2_since_week                      float64\n",
       "promo2_since_year                      float64\n",
       "promo_interval                          object\n",
       "month_map                               object\n",
       "is_promo                                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4519616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['competition_open_since_month'] = df1['competition_open_since_month'].astype('int64')\n",
    "df1['competition_open_since_year'] = df1['competition_open_since_year'].astype('int64')\n",
    "df1['promo2_since_week'] = df1['promo2_since_week'].astype('int64')\n",
    "df1['promo2_since_year'] = df1['promo2_since_year'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c24c5a",
   "metadata": {},
   "source": [
    "## 1.4 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89f4815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attributes = df1.select_dtypes(include = ['int64', 'float64'])\n",
    "cat_attributes = df1.select_dtypes(exclude = ['int64', 'float64', 'datetime64[ns]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460d8af6",
   "metadata": {},
   "source": [
    "# 2.0 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4aa8afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f0f321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year\n",
    "df2['year'] = df2['date'].dt.year\n",
    "\n",
    "# month\n",
    "df2['month'] = df2['date'].dt.month\n",
    "\n",
    "# day\n",
    "df2['day'] = df2['date'].dt.day\n",
    "\n",
    "# week of year\n",
    "df2['week_of_year'] = df2['date'].dt.isocalendar().week\n",
    "\n",
    "# year week\n",
    "df2['year_week'] = df2['date'].dt.strftime('%Y-%W')\n",
    "\n",
    "# competition since\n",
    "df2['competition_since'] = df2.apply(lambda x: dtt.datetime(year=x['competition_open_since_year'],\n",
    "                                                                 month=x['competition_open_since_month'],\n",
    "                                                                 day=1), axis=1)\n",
    "\n",
    "df2['competition_time_month'] = ((df2['date'] - df2['competition_since'])/30).apply(lambda x: x.days).astype('int64')\n",
    "\n",
    "# promo since\n",
    "df2['promo_since'] = df2['promo2_since_year'].astype(str) + '-' + df2['promo2_since_week'].astype(str)\n",
    "\n",
    "df2['promo_since'] = df2['promo_since'].apply(\n",
    "    lambda x: dtt.datetime.strptime(x + '-1', '%Y-%W-%w') - dtt.timedelta(days = 7))\n",
    "\n",
    "df2['promo_time_week'] = ((df2['date'] - df2['promo_since'])/7).apply(lambda x: x.days).astype('int64')\n",
    "\n",
    "# assortment\n",
    "df2['assortment'] = df2['assortment'].apply(lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended')\n",
    "\n",
    "# state holiday\n",
    "df2['state_holiday'] = df2['state_holiday'].apply(\n",
    "    lambda x: 'public_holiday' if x == 'a' else 'easter' if x == 'b' else 'christmas' if x == 'c' else 'regular_day')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ec64d",
   "metadata": {},
   "source": [
    "# 3.0 Variable filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98311c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d165916c",
   "metadata": {},
   "source": [
    "## 3.1 Index filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a376316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3[(df3['open'] != 0) & (df3['sales'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de794b20",
   "metadata": {},
   "source": [
    "## 3.2 Column selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdfab942",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['customers', 'open', 'promo_interval', 'month_map']\n",
    "df3 = df3.drop(cols_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ce3f32",
   "metadata": {},
   "source": [
    "# 4.0 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2522b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f411c3",
   "metadata": {},
   "source": [
    "## 4.1 Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a28a4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df5.select_dtypes(include=['int64', 'float64'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f4a88df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RobustScaler()\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "#competition distance\n",
    "df4['competition_distance'] = rs.fit_transform(df5[['competition_distance']].values)\n",
    "pickle.dump(rs, open(r'C:\\Users\\jota_\\Repositorios\\DS_producao\\webapp1\\parameter\\competition_distance_scaler.pkl', 'wb'))\n",
    "\n",
    "#year\n",
    "df4['year'] = mms.fit_transform(df5[['year']].values)\n",
    "pickle.dump(mms, open(r'C:\\Users\\jota_\\Repositorios\\DS_producao\\webapp1\\parameter\\year_scaler.pkl', 'wb'))\n",
    "\n",
    "#competition time month\n",
    "df4['competition_time_month'] = rs.fit_transform(df5[['competition_time_month']].values)\n",
    "pickle.dump(rs, open(r'C:\\Users\\jota_\\Repositorios\\DS_producao\\webapp1\\parameter\\competition_time_month_scaler.pkl', 'wb'))\n",
    "\n",
    "#promo time week\n",
    "df4['promo_time_week'] = mms.fit_transform(df5[['promo_time_week']].values)\n",
    "pickle.dump(rs, open(r'C:\\Users\\jota_\\Repositorios\\DS_producao\\webapp1\\parameter\\promo_time_week_scaler.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c219410d",
   "metadata": {},
   "source": [
    "## 4.2 Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e249a3d",
   "metadata": {},
   "source": [
    "### 4.2.1 Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13f9e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_holiday - one hot encoding\n",
    "df4 = pd.get_dummies(df4, prefix=['state_holiday'], columns=['state_holiday'])\n",
    "# store_type - Label encoding\n",
    "le = LabelEncoder()\n",
    "df4['store_type'] = le.fit_transform(df4['store_type'])\n",
    "pickle.dump(le, open(r'C:\\Users\\jota_\\Repositorios\\DS_producao\\webapp1\\parameter\\store_type_scaler.pkl', 'wb'))\n",
    "\n",
    "#assortment - ordinal encoding\n",
    "assortment_dict = {'basic': 1,\n",
    "                 'extended': 3, \n",
    "                 'extra': 2}\n",
    "df4['assortment'] = df4['assortment'].map(assortment_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d47517",
   "metadata": {},
   "source": [
    "### 4.2.2 Response Variable Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b84f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['sales'] = np.log1p(df4['sales'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b326be88",
   "metadata": {},
   "source": [
    "### 4.2.3 Nature Transformation - Cyclical Nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca593ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# month\n",
    "df4['month_sin'] = df4['month'].apply(lambda x: np.sin( x * ( 2 * np.pi/12 )))\n",
    "df4['month_cos'] = df4['month'].apply(lambda x: np.cos( x * ( 2 * np.pi/12 )))\n",
    "\n",
    "# day\n",
    "df4['day_sin'] = df4['day'].apply(lambda x: np.sin( x * ( 2 * np.pi/30 )))\n",
    "df4['day_cos'] = df4['day'].apply(lambda x: np.cos( x * ( 2 * np.pi/30 )))\n",
    "\n",
    "# week of year\n",
    "df4['week_of_year_sin'] = df4['week_of_year'].apply(lambda x: np.sin( x * ( 2 * np.pi/52 )))\n",
    "df4['week_of_year_cos'] = df4['week_of_year'].apply(lambda x: np.cos( x * ( 2 * np.pi/52 )))\n",
    "\n",
    "# day of week\n",
    "df4['day_of_week_sin'] = df4['day_of_week'].apply(lambda x: np.sin( x * ( 2 * np.pi/7 )))\n",
    "df4['day_of_week_cos'] = df4['day_of_week'].apply(lambda x: np.cos( x * ( 2 * np.pi/7 )))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18cffa3",
   "metadata": {},
   "source": [
    "# 5.0 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0bff65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bc7215",
   "metadata": {},
   "source": [
    "## 5.1 Split dataframe into training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d15a877b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols_drop = ['month', 'week_of_year', 'day_of_week', 'day', 'promo_since', 'competition_since', 'year_week']\n",
    "df5 = df5.drop(cols_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbfa779b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2015-06-19 00:00:00')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5[['date', 'store']].groupby('store').max().reset_index()['date'][0] - dtt.timedelta(days=6*7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3675e445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Min Date: 2013-01-01 00:00:00\n",
      "Training Max Date: 2015-06-18 00:00:00\n",
      "Test Min Date: 2015-06-19 00:00:00\n",
      "Test Max Date: 2015-07-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#training dataset\n",
    "X_train = df5[df5['date'] < '2015-06-19']\n",
    "Y_train = X_train['sales']\n",
    "\n",
    "#test dataset\n",
    "X_test = df5[df5['date'] >= '2015-06-19']\n",
    "Y_test = X_test['sales']\n",
    "\n",
    "print('Training Min Date: {}'.format(X_train['date'].min()))\n",
    "print('Training Max Date: {}'.format(X_train['date'].max()))\n",
    "\n",
    "print('Test Min Date: {}'.format(X_test['date'].min()))\n",
    "print('Test Max Date: {}'.format(X_test['date'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9f40536",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_selected_boruta = [\n",
    "     'store',\n",
    "     'promo',\n",
    "     'store_type',\n",
    "     'assortment',\n",
    "     'competition_distance',\n",
    "     'competition_open_since_month',\n",
    "     'competition_open_since_year',\n",
    "     'promo2',\n",
    "     'promo2_since_week',\n",
    "     'promo2_since_year',\n",
    "     'competition_time_month',\n",
    "     'promo_time_week',\n",
    "     'month_cos',\n",
    "     'month_sin',\n",
    "     'day_sin',\n",
    "     'day_cos',\n",
    "     'week_of_year_cos',\n",
    "     'week_of_year_sin',\n",
    "     'day_of_week_sin',\n",
    "     'day_of_week_cos']\n",
    "\n",
    "#columns to add\n",
    "feat_to_add = ['date', 'sales']\n",
    "\n",
    "#final features\n",
    "cols_selected_boruta_full = cols_selected_boruta.copy()\n",
    "cols_selected_boruta_full.extend(feat_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a22e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_not_selected_boruta = [\n",
    "     'is_promo',\n",
    "     'school_holiday',\n",
    "     'state_holiday_christmas',\n",
    "     'state_holiday_easter',\n",
    "     'state_holiday_public_holiday',\n",
    "     'state_holiday_regular_day',\n",
    "     'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1b78266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['store',\n",
       " 'promo',\n",
       " 'store_type',\n",
       " 'assortment',\n",
       " 'competition_distance',\n",
       " 'competition_open_since_month',\n",
       " 'competition_open_since_year',\n",
       " 'promo2',\n",
       " 'promo2_since_week',\n",
       " 'promo2_since_year',\n",
       " 'competition_time_month',\n",
       " 'promo_time_week',\n",
       " 'month_cos',\n",
       " 'month_sin',\n",
       " 'day_sin',\n",
       " 'day_cos',\n",
       " 'week_of_year_cos',\n",
       " 'week_of_year_sin',\n",
       " 'day_of_week_sin',\n",
       " 'day_of_week_cos']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_selected_boruta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ed74d",
   "metadata": {},
   "source": [
    "# 6.0 Machine Learning Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ce57fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train[cols_selected_boruta]\n",
    "x_test = X_test[cols_selected_boruta]\n",
    "\n",
    "#time series data preparation\n",
    "x_training = X_train[cols_selected_boruta_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f267518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_tuned = {\n",
    "    'n_estimators': 2500, \n",
    "    'eta': 0.01, \n",
    "    'max_depth': 9, \n",
    "    'subsample': 0.7, \n",
    "    'colsample_bytree': 0.3, \n",
    "    'min_child_weight': 8}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3d50579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>6994.372141</td>\n",
       "      <td>0.999866</td>\n",
       "      <td>7628.056609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model name          MAE      MAPE         RMSE\n",
       "0  XGBoost Regressor  6994.372141  0.999866  7628.056609"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "model_xgb_tuned = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                             n_estimators=param_tuned['n_estimators'], \n",
    "                             eta=param_tuned['eta'], \n",
    "                             max_depth=param_tuned['max_depth'], \n",
    "                             subsample=param_tuned['subsample'], \n",
    "                             colsample_bytree=param_tuned['colsample_bytree'], \n",
    "                             min_child_weight=param_tuned['min_child_weight']).fit(x_train, Y_train)\n",
    "\n",
    "# prediction\n",
    "yhat_xgb_tuned = model_xgb_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# performance\n",
    "xgb_result_tuned = ml_error('XGBoost Regressor', np.expm1(Y_test), np.expm1(yhat_xgb_tuned))\n",
    "xgb_result_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67430b66",
   "metadata": {},
   "source": [
    "# 7.0 Error interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e29de788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = X_test[cols_selected_boruta_full]\n",
    "\n",
    "# rescale\n",
    "df6['sales'] = np.expm1(df6['sales'])\n",
    "df6['predictions'] = np.expm1(yhat_xgb_tuned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b777f8f",
   "metadata": {},
   "source": [
    "## 7.1 Business Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56dd9cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of predictions\n",
    "\n",
    "df7 = df6[['store', 'predictions']].groupby('store').sum().reset_index()\n",
    "\n",
    "# MAE and MAPE\n",
    "df6_aux1 = df6[['store', 'sales', 'predictions']].groupby('store').apply(lambda x: mean_absolute_error(x['sales'], x['predictions'])).reset_index().rename(columns={0: 'MAE'})\n",
    "df6_aux2 = df6[['store', 'sales', 'predictions']].groupby('store').apply(lambda x: mean_absolute_percentage_error(x['sales'], x['predictions'])).reset_index().rename(columns={0: 'MAPE'})\n",
    "\n",
    "# Merge\n",
    "df6_aux3 = pd.merge(df6_aux1, df6_aux2, how='inner', on='store')\n",
    "df8 = pd.merge(df7, df6_aux3, how='inner', on='store')\n",
    "\n",
    "# Scenarios\n",
    "df8['worst_scenario'] = df8['predictions'] - df8['MAE']\n",
    "df8['best_scenario'] = df8['predictions'] + df8['MAE']\n",
    "\n",
    "# order columns\n",
    "df8 = df8[['store', 'predictions', 'worst_scenario', 'best_scenario', 'MAE', 'MAPE']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856e41b1",
   "metadata": {},
   "source": [
    "## 7.2 Total Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c1de5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenarios</th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>predictions</td>\n",
       "      <td>R$32,720.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best_scenario</td>\n",
       "      <td>R$7,824,102.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>worst_scenario</td>\n",
       "      <td>R$-7,758,661.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Scenarios           Values\n",
       "0     predictions      R$32,720.84\n",
       "1   best_scenario   R$7,824,102.98\n",
       "2  worst_scenario  R$-7,758,661.29"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9 = df8[['predictions', 'best_scenario', 'worst_scenario']].apply(lambda x: np.sum(x), axis=0).reset_index().rename(columns={'index': 'Scenarios', 0: 'Values'})\n",
    "df9['Values'] = df9['Values'].map('R${:,.2f}'.format)\n",
    "df9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a94fa3",
   "metadata": {},
   "source": [
    "## 7.3 Machine Learning Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a0127a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['error'] = df6['sales'] - df6['predictions']\n",
    "df6['error_rate'] = df6['predictions'] / df6['sales']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b32c99",
   "metadata": {},
   "source": [
    "# 8.0 Deploy Model to Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6990de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "pickle.dump(model_xgb_tuned, open(r'C:\\Users\\jota_\\Repositorios\\DS_producao\\model_rossmann_xgb.pkl', 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3d395f",
   "metadata": {},
   "source": [
    "## 8.1 Rosmann Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154e9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime as dtt\n",
    "import pickle\n",
    "import inflection\n",
    "\n",
    "class Rossmann(object):\n",
    "    def __init__(self):\n",
    "        self.home_path = '/Users/jota_/Repositorios/DS_producao/'\n",
    "        self.competition_distance_scaler = pickle.load(open(self.home_path + 'parameter/competition_distance_scaler.pkl', 'rb'))\n",
    "        self.competition_time_month_scaler = pickle.load(open(self.home_path + 'parameter/competition_time_month_scaler.pkl', 'rb'))\n",
    "        self.promo_time_week_scaler = pickle.load(open(self.home_path + 'parameter/promo_time_week_scaler.pkl', 'rb'))\n",
    "        self.year_scaler = pickle.load(open(self.home_path + 'parameter/year_scaler.pkl', 'rb'))\n",
    "        self.store_type_scaler = pickle.load(open(self.home_path + 'parameter/store_type_scaler.pkl', 'rb'))\n",
    "\n",
    "      \n",
    "    def data_cleaning(self, df1):\n",
    "        cols_old = ['Store', 'DayOfWeek', 'Date', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', \n",
    "            'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', \n",
    "            'Promo2', 'Promo2SinceWeek','Promo2SinceYear', 'PromoInterval']\n",
    "        \n",
    "        snakecase = lambda x: inflection.underscore(x)\n",
    "\n",
    "        cols_new = list(map(snakecase, cols_old))\n",
    "\n",
    "        #Rename\n",
    "        df1.columns = cols_new\n",
    "\n",
    "        df1['date'] = pd.to_datetime(df1['date'])\n",
    "\n",
    "        #competition_distance             \n",
    "        df1['competition_distance'] = df1['competition_distance'].apply(lambda x: 200000.0 if math.isnan(x) else x)\n",
    "\n",
    "        #competition_open_since_month    \n",
    "\n",
    "        df1['competition_open_since_month'] = df1.apply(lambda x: x['date'].month if math.isnan(x['competition_open_since_month']) \n",
    "                                                        else x['competition_open_since_month'], axis=1) \n",
    "\n",
    "        #competition_open_since_year     \n",
    "\n",
    "        df1['competition_open_since_year'] = df1.apply(lambda x: x['date'].year if math.isnan(x['competition_open_since_year']) \n",
    "                                                        else x['competition_open_since_year'], axis=1) \n",
    "\n",
    "        #promo2_since_week    \n",
    "        df1['promo2_since_week'] = df1.apply(lambda x: x['date'].week if math.isnan(x['promo2_since_week']) \n",
    "                                                        else x['promo2_since_week'], axis=1)\n",
    "\n",
    "        #promo2_since_year               \n",
    "        df1['promo2_since_year'] = df1.apply(lambda x: x['date'].year if math.isnan(x['promo2_since_year']) \n",
    "                                                        else x['promo2_since_year'], axis=1)\n",
    "\n",
    "        #promo_interval\n",
    "        df1['promo_interval'].fillna(0, inplace=True)\n",
    "\n",
    "        month_map = {1: 'Jan', 2: 'Fev', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', \n",
    "                     7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "\n",
    "        df1['month_map'] = df1['date'].dt.month.map(month_map)\n",
    "\n",
    "        df1['is_promo'] = df1[['promo_interval', 'month_map']].apply(\n",
    "            lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split(',') else 0, axis=1)\n",
    "        \n",
    "        return df1\n",
    "    \n",
    "    def feature_engineering(self, df2):\n",
    "        # year\n",
    "        df2['year'] = df2['date'].dt.year\n",
    "\n",
    "        # month\n",
    "        df2['month'] = df2['date'].dt.month\n",
    "\n",
    "        # day\n",
    "        df2['day'] = df2['date'].dt.day\n",
    "\n",
    "        # week of year\n",
    "        df2['week_of_year'] = df2['date'].dt.isocalendar().week\n",
    "\n",
    "        # year week\n",
    "        df2['year_week'] = df2['date'].dt.strftime('%Y-%W')\n",
    "\n",
    "\n",
    "        # competition since\n",
    "        df2['competition_since'] = df2.apply(lambda x: dtt.datetime(year=x['competition_open_since_year'],\n",
    "                                                                         month=x['competition_open_since_month'],\n",
    "                                                                         day=1), axis=1)\n",
    "        df2['competition_time_month'] = ((df2['date'] - df2['competition_since'])/30).apply(lambda x: x.days).astype('int64')\n",
    "\n",
    "        # promo since\n",
    "        df2['promo_since'] = df2['promo2_since_year'].astype(str) + '-' + df2['promo2_since_week'].astype(str)\n",
    "\n",
    "        df2['promo_since'] = df2['promo_since'].apply(\n",
    "            lambda x: dtt.datetime.strptime(x + '-1', '%Y-%W-%w') - dtt.timedelta(days = 7))\n",
    "\n",
    "        df2['promo_time_week'] = ((df2['date'] - df2['promo_since'])/7).apply(lambda x: x.days).astype('int64')\n",
    "\n",
    "\n",
    "        # assortment\n",
    "        df2['assortment'] = df2['assortment'].apply(lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended')\n",
    "\n",
    "\n",
    "        # state holiday\n",
    "        df2['state_holiday'] = df2['state_holiday'].apply(\n",
    "            lambda x: 'public_holiday' if x == 'a' else 'easter' if x == 'b' else 'christmas' if x == 'c' else 'regular_day')\n",
    "        \n",
    "        df2 = df2[df2['open'] != 0]\n",
    "        \n",
    "        cols_drop = ['open', 'promo_interval', 'month_map']\n",
    "        df2 = df2.drop(cols_drop, axis=1)\n",
    "        \n",
    "        return df2\n",
    "    \n",
    "    def data_preparation(self, df5):\n",
    "        \n",
    "        #competition distance\n",
    "        df5['competition_distance'] = self.competition_distance_scaler.fit_transform(df5[['competition_distance']].values)\n",
    "\n",
    "        # year\n",
    "        df5['year'] = self.year_scaler.fit_transform(df5[['year']].values)\n",
    "\n",
    "        # competition time month\n",
    "        df5['competition_time_month'] = self.competition_time_month_scaler.fit_transform(df5[['competition_time_month']].values)\n",
    "\n",
    "        # promo time week\n",
    "        df5['promo_time_week'] = self.promo_time_week_scaler.fit_transform(df5[['promo_time_week']].values)\n",
    "        \n",
    "        # state_holiday - one hot encoding\n",
    "        df5 = pd.get_dummies(df5, prefix=['state_holiday'], columns=['state_holiday'])\n",
    "        \n",
    "        # store_type - Label encoding\n",
    "        df5['store_type'] = self.store_type_scaler.fit_transform(df5['store_type'])\n",
    "\n",
    "        #assortment - ordinal encoding\n",
    "        assortment_dict = {'basic': 1,\n",
    "                         'extended': 3, \n",
    "                         'extra': 2}\n",
    "        df5['assortment'] = df5['assortment'].map(assortment_dict)\n",
    "\n",
    "        # month\n",
    "        df5['month_sin'] = df5['month'].apply(lambda x: np.sin( x * ( 2 * np.pi/12 )))\n",
    "        df5['month_cos'] = df5['month'].apply(lambda x: np.cos( x * ( 2 * np.pi/12 )))\n",
    "\n",
    "        # day\n",
    "        df5['day_sin'] = df5['day'].apply(lambda x: np.sin( x * ( 2 * np.pi/30 )))\n",
    "        df5['day_cos'] = df5['day'].apply(lambda x: np.cos( x * ( 2 * np.pi/30 )))\n",
    "\n",
    "        # week of year\n",
    "        df5['week_of_year_sin'] = df5['week_of_year'].apply(lambda x: np.sin( x * ( 2 * np.pi/52 )))\n",
    "        df5['week_of_year_cos'] = df5['week_of_year'].apply(lambda x: np.cos( x * ( 2 * np.pi/52 )))\n",
    "\n",
    "        # day of week\n",
    "        df5['day_of_week_sin'] = df5['day_of_week'].apply(lambda x: np.sin( x * ( 2 * np.pi/7 )))\n",
    "        df5['day_of_week_cos'] = df5['day_of_week'].apply(lambda x: np.cos( x * ( 2 * np.pi/7 )))\n",
    "        \n",
    "        cols_selected = [\n",
    "             'store',\n",
    "             'promo',\n",
    "             'store_type',\n",
    "             'assortment',\n",
    "             'competition_distance',\n",
    "             'competition_open_since_month',\n",
    "             'competition_open_since_year',\n",
    "             'promo2',\n",
    "             'promo2_since_week',\n",
    "             'promo2_since_year',\n",
    "             'competition_time_month',\n",
    "             'promo_time_week',\n",
    "             'month_cos',\n",
    "             'month_sin',\n",
    "             'day_sin',\n",
    "             'day_cos',\n",
    "             'week_of_year_cos',\n",
    "             'week_of_year_sin',\n",
    "             'day_of_week_sin',\n",
    "             'day_of_week_cos']\n",
    "        \n",
    "        return df5[cols_selected]\n",
    "    \n",
    "    def get_prediction(self, model, original_data, test_data):\n",
    "        #prediction\n",
    "        pred = model.predict(test_data)\n",
    "        \n",
    "        #join pred into the original data\n",
    "        original_data['prediction'] = np.expm1(pred)\n",
    "        \n",
    "        return original_data.to_json(orient = 'records', date_format='iso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307a5ed",
   "metadata": {},
   "source": [
    "## 8.2 API Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaac850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, Response\n",
    "from rossmann.Rossmann import Rossmann\n",
    "\n",
    "# loading model\n",
    "model = pickle.load(open('/Users/jota_/Repositorios/DS_producao/model_rossmann_final2.pkl', 'rb'))\n",
    "\n",
    "# initialize api\n",
    "app = Flask( __name__ )\n",
    "\n",
    "@app.route('/rossmann/predict', methods=['POST'])\n",
    "def rossmann_predict():\n",
    "    test_json = request.get_json()\n",
    "    \n",
    "    if test_json:\n",
    "        \n",
    "        if isinstance(test_json, dict): #unique exmple\n",
    "            test_raw = pd.DataFrame(test_json, index=[0])\n",
    "        else: # multiple examples\n",
    "            test_raw = pd.DataFrame(test_json, columns=test_json[0].keys())\n",
    "            \n",
    "        #instantiate rossmann class\n",
    "        pipeline = Rossmann()\n",
    "        \n",
    "        # data cleaning\n",
    "        df1 = pipeline.data_cleaning(test_raw)\n",
    "        \n",
    "        # feature engineering\n",
    "        df2 = pipeline.feature_engineering(df1)\n",
    "        \n",
    "        # data preparation\n",
    "        df3 = pipeline.data_preparation(df2)\n",
    "        \n",
    "        # prediction\n",
    "        df_response = pipeline.get_prediction(model, test_raw, df3)\n",
    "        \n",
    "        return df_response\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        return Response('{}', status=200, mimetype='application/json')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run('0.0.0.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cddec7e",
   "metadata": {},
   "source": [
    "## 8.3 API Tester "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4bd25ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test dataset\n",
    "df10 = pd.read_csv(r'C:\\Users\\jota_\\Repositorios\\DS_producao\\Datasets_ds\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "593f76d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge test dataset + store\n",
    "df_test = pd.merge(df10, df_store_raw, how='left', on='Store')\n",
    "\n",
    "# choose store for prediction \n",
    "df_test = df_test[df_test['Store'].isin([12, 22, 24])]\n",
    "# remove closed days\n",
    "df_test = df_test[df_test['Open'] != 0]\n",
    "df_test = df_test[~df_test['Open'].isnull()]\n",
    "df_test = df_test.drop('Id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4118b508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataframe to json\n",
    "data = json.dumps(df_test.to_dict(orient='records'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfec3923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code 200\n"
     ]
    }
   ],
   "source": [
    "# API call\n",
    "url = 'https://rossmann-model-jl1.herokuapp.com/rossmann/predict'\n",
    "header = {'Content-type': 'application/json'}\n",
    "data = data\n",
    "\n",
    "r = requests.post(url, data=data, headers=header)\n",
    "print('Status Code {}'.format(r.status_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8700bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame(r.json(),columns = r.json()[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3e7f193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store Number 12 will sell R$224,511.73 in the next 6 weeks\n",
      "Store Number 22 will sell R$201,874.37 in the next 6 weeks\n",
      "Store Number 24 will sell R$284,107.18 in the next 6 weeks\n"
     ]
    }
   ],
   "source": [
    "d2 =d1[['store', 'prediction']].groupby('store').sum().reset_index()\n",
    "\n",
    "for i in range(len(d2)):\n",
    "    print('Store Number {} will sell R${:,.2f} in the next 6 weeks'.format(\n",
    "    d2.loc[i, 'store'],\n",
    "    d2.loc[i, 'prediction']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
